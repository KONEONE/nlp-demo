{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1hWQ3DTlsKywFHDGJs2pPegwc5pf9fr0S",
      "authorship_tag": "ABX9TyOShufRZd04GL7n/4fUL37y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "963ffe4adc4a46e397c0053a2641462e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3010163abc39461383aff863b16897dd",
              "IPY_MODEL_6582f70cfdf64bc5861deb4c13381638",
              "IPY_MODEL_812cfecbb2b14b0db18ab3cfdf17821e"
            ],
            "layout": "IPY_MODEL_545c498e96e64cc89731b2c2af6bcc3b"
          }
        },
        "3010163abc39461383aff863b16897dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28809eedd40e4d47bc82bd74ffd3dad9",
            "placeholder": "​",
            "style": "IPY_MODEL_c7a1870238c047d6b1560e29d90360a9",
            "value": "Parsing nodes: 100%"
          }
        },
        "6582f70cfdf64bc5861deb4c13381638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f49382e7cd4b6d8c51d540435e6326",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9748cd9e5924bcf993c3223b8c5edb4",
            "value": 7
          }
        },
        "812cfecbb2b14b0db18ab3cfdf17821e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1227ef503d43be9b4db578ecf21317",
            "placeholder": "​",
            "style": "IPY_MODEL_9c62252459c543efa59cfbeabf2b1b0d",
            "value": " 7/7 [00:00&lt;00:00, 21.47it/s]"
          }
        },
        "545c498e96e64cc89731b2c2af6bcc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28809eedd40e4d47bc82bd74ffd3dad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a1870238c047d6b1560e29d90360a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2f49382e7cd4b6d8c51d540435e6326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9748cd9e5924bcf993c3223b8c5edb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a1227ef503d43be9b4db578ecf21317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c62252459c543efa59cfbeabf2b1b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KONEONE/nlp-demo/blob/main/llamaindex_load_doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLAMAINDEX 加载 文档\n",
        "这篇笔记是记录llamaidnex加载文档的学习笔记  \n",
        "## 加载  \n",
        "* SimpleDirectoryReader： 用于本地目录加载各种文件类型的加载  \n",
        "* LlamaParse: LlammaIndex官方的PDF解析工具，作为托管API提供\n",
        "* LlamaHub: 包含了数百个数据加载库的注册中心  \n",
        "## 转换  \n",
        "* 节点解析器：  \n",
        "* 节点解析器模块：\n",
        "## 整合所有内容  \n",
        "设置一个可重复、缓存优化的加载数据的过程\n",
        "## 高级\n",
        "文档和节点对象以及高级使用"
      ],
      "metadata": {
        "id": "EA-WeJKB3__9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beN9Bh5k3giI"
      },
      "outputs": [],
      "source": [
        "# 安装依赖\n",
        "%pip install llama-index-core\n",
        "%pip install llama-index-llms-dashscope\n",
        "%pip install llama-index-indices-managed-dashscope\n",
        "%pip install llama-index-embeddings-openai\n",
        "%pip install llama-index-readers-file\n",
        "%pip install llama-index-vector-stores-qdrant\n",
        "%pip install qdrant-client\n",
        "%pip install llama-index-storage-kvstore-redis\n",
        "%pip install redis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DASHSCOPE_API_KEY\"] = 'sk-a49fcd63a06f4b669c38b1461a60d2e4'"
      ],
      "metadata": {
        "id": "qCmsegNUFZZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Settings\n",
        "from llama_index.llms.dashscope import DashScope\n",
        "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
        "\n",
        "# 将LlamaIndex的embeding model 设置为百炼\n",
        "Settings.embed_model = DashScopeEmbedding(model_name=\"text-embedding-v1\", api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
        "\n",
        "# 将LlamaIndex的llm model 设置为百炼\n",
        "Settings.llm = DashScope(model_name=\"qwen-plus\", api_key=os.getenv(\"DASHSCOPE_API_KEY\"))"
      ],
      "metadata": {
        "id": "6PrFTn32Fe4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文档&节点 - 概述"
      ],
      "metadata": {
        "id": "h40vwpMDD07Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 根据文档构建索引\n",
        "from llama_index.core import Document, VectorStoreIndex\n",
        "\n",
        "test_list = [\"风急天高猿啸哀\", \"渚清沙白鸟飞回\", \"无边落木萧萧下\", \"不尽长江滚滚来\"]\n",
        "documents = [Document(text=t) for t in test_list]\n",
        "\n",
        "# 构建index\n",
        "indexs = VectorStoreIndex.from_documents(documents=documents)"
      ],
      "metadata": {
        "id": "rpPT99_lD7TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 根据Node构建索引\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "# doc -段落切割-> node\n",
        "parser = SentenceSplitter()\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "# 构建node_index\n",
        "node_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "5H7jrUHbEqEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 文档使用  "
      ],
      "metadata": {
        "id": "lNzUitMhH56R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 加载文件生成doc\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "base_dir = \"./drive/MyDrive/data/llamaData\"\n",
        "baseDocuments = SimpleDirectoryReader(base_dir).load_data()\n",
        "\n",
        "for d in baseDocuments:\n",
        "  print(f'{d.id_} - {d.get_type()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iouataSaHzmt",
        "outputId": "fe51899d-37f2-4e51-a9e2-ad5a05ea99d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3c91a058-d220-4aef-a7aa-680d3bf5fa2c - ObjectType.DOCUMENT\n",
            "3cfeb273-a142-4853-a7e3-a2a3643502bc - ObjectType.DOCUMENT\n",
            "7f9e44bf-afa7-4066-9ff6-39acd6598bfa - ObjectType.DOCUMENT\n",
            "e602f7c7-d3df-4b63-bee1-1af1dd18c569 - ObjectType.DOCUMENT\n",
            "a4b22999-30f6-4960-955a-dea60d47e4e9 - ObjectType.DOCUMENT\n",
            "536aa21e-6631-4953-a028-272425c3c0c5 - ObjectType.DOCUMENT\n",
            "ea132ae9-5f1a-4033-944d-0871c38e47ea - ObjectType.DOCUMENT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 手动生成doc\n",
        "from llama_index.core import Document\n",
        "\n",
        "test_list = [\"风急天高猿啸哀\", \"渚清沙白鸟飞回\", \"无边落木萧萧下\", \"不尽长江滚滚来\"]\n",
        "testDocuments = [Document(text=t) for t in test_list]\n",
        "\n",
        "for d in testDocuments:\n",
        "  print(f'{d.id_} - {d.get_type()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0pYFsdHJB24",
        "outputId": "0c6663fb-0726-4d5e-dcc8-f2cf8079037f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27e89aa5-7057-427f-9e48-3d90fd5418bb - ObjectType.DOCUMENT\n",
            "cb671995-1bd6-461a-b5f9-6253ad325929 - ObjectType.DOCUMENT\n",
            "d40ddca0-dc4f-486c-baa8-7ef396133354 - ObjectType.DOCUMENT\n",
            "9a5e9433-6836-4f71-8a98-ef4efd4e6c7d - ObjectType.DOCUMENT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 自定义文档  \n",
        "任何在文档的metadata字典中设置的信息都会显示在该文档创建的每个源节点metadata中。这些信息包含在节点中，使索引能够在查询和响应中利用它。默认情况下，元数据会注入文本中，用于嵌入和LLM模型调用  \n"
      ],
      "metadata": {
        "id": "GlkZevpwOh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for d in baseDocuments:\n",
        "  print(f'{d.metadata}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCpL9AUCOafV",
        "outputId": "8ef91e7a-f6f2-4183-b6fd-431c07ddcf25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'file_path': '/content/drive/MyDrive/data/llamaData/Bigdata_面试.md', 'file_name': 'Bigdata_面试.md', 'file_type': 'text/markdown', 'file_size': 21604, 'creation_date': '2025-08-31', 'last_modified_date': '2025-04-30'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/bigdata_数据仓库建模.md', 'file_name': 'bigdata_数据仓库建模.md', 'file_type': 'text/markdown', 'file_size': 30751, 'creation_date': '2025-08-31', 'last_modified_date': '2025-04-30'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/卷积神经网络.md', 'file_name': '卷积神经网络.md', 'file_type': 'text/markdown', 'file_size': 9486, 'creation_date': '2025-08-31', 'last_modified_date': '2025-07-22'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/多项式回归.md', 'file_name': '多项式回归.md', 'file_type': 'text/markdown', 'file_size': 7734, 'creation_date': '2025-08-31', 'last_modified_date': '2025-07-22'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/孤立森林.md', 'file_name': '孤立森林.md', 'file_type': 'text/markdown', 'file_size': 10520, 'creation_date': '2025-08-31', 'last_modified_date': '2025-07-22'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/局部离群因子.md', 'file_name': '局部离群因子.md', 'file_type': 'text/markdown', 'file_size': 13289, 'creation_date': '2025-08-31', 'last_modified_date': '2025-07-22'}\n",
            "{'file_path': '/content/drive/MyDrive/data/llamaData/层次聚类.md', 'file_name': '层次聚类.md', 'file_type': 'text/markdown', 'file_size': 13026, 'creation_date': '2025-08-31', 'last_modified_date': '2025-07-22'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 使用Node  \n",
        "在llamaindex中构建节点关系（relationships）是构建结构化知识图谱的关键机制，它使得节点之间形成有意义的连接，这些关系对如下场景非常重要：  \n",
        "1. 保持文档结构  \n",
        "1.1 当原始文档被拆分为多个节点时，关系可以重建原始顺序  \n",
        "1.2 Next/Previous关系维护文本的连续性，就像链表一样链接节点  \n",
        "2. 增强索引质量  \n",
        "2.1 索引时可以获取相关节点（如前\\后文）提供更加完整的上下文    \n",
        "2.2 示例：回答问题时，获取匹配节点的前后文能提高答案准确性  \n",
        "3. 构建知识图谱  \n",
        "3.1 表示概念间的语义关系（如父子、引用等）  \n",
        "3.2 PARENT、CHILD关系可以构建层次结构  \n",
        "4. 图遍历能力  \n",
        "4.1 支持复杂查询  \n",
        "4.2 实现多跳推理  \n"
      ],
      "metadata": {
        "id": "34Awxea9Qszf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
        "\n",
        "# 创建2个连续文本带你\n",
        "node1 = TextNode(text=\"段落1\", id=\"node01\")\n",
        "node2 = TextNode(text=\"段落2\", id=\"node02\")\n",
        "\n",
        "# 创建双向连接关系\n",
        "node1.relationships[NodeRelationship.NEXT] = RelatedNodeInfo(node_id=\"node02\")  # node1 下一个节点：node2\n",
        "node2.relationships[NodeRelationship.PREVIOUS] = RelatedNodeInfo(node_id=\"node01\") # node2 下一个节点： node1"
      ],
      "metadata": {
        "id": "q0CLz3gbQsTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面给出了NodeRelationship的一些常用关系：\n",
        "\n",
        "|关系类型 |\t说明\t| 典型应用|  \n",
        "|----|----|----|  \n",
        "|NEXT\t|下一个节点|\t连续文本|\n",
        "|PREVIOUS\t|前一个节点\t|连续文本|\n",
        "|PARENT\t|父节点\t|章节结构|\n",
        "|CHILD\t|子节点\t|章节结构|\n",
        "|SOURCE\t|源文档\t|节点溯源|\n",
        "|REFERENCE\t|引用节点\t|跨文档链接|\n",
        "|CONTEXT\t|相关上下文\t|补充信息|\n",
        "\n",
        "\n",
        "### 元数据提取  \n",
        "元数据模块包含以下“特征提取器”：  \n",
        "* SummaryExtractor : 自动从一组节点中提取摘要  \n",
        "* QuestionsAnsweredExtractor: 提取每个接待您可以回答的一组问题  \n",
        "* TitleExtractor: 从每个节点的上下文提取标题\n",
        "* EntityExtractor: 提取每个节点内容中提到的实体（地点、人物、事务等）  "
      ],
      "metadata": {
        "id": "-FK17mQEjRWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入元数据提取器和节点解析器\n",
        "from llama_index.core.extractors import (\n",
        "    TitleExtractor, QuestionsAnsweredExtractor\n",
        ")\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "\n",
        "# 1. 创建文本分割器（节点解析器）\n",
        "text_splitter = TokenTextSplitter(\n",
        "    separator=\" \",      # 使用空格作为分隔符\n",
        "    chunk_size=512,     # 每个节点的最大token数量\n",
        "    chunk_overlap=128   # 节点间重叠token数量\n",
        ")\n",
        "\n",
        "# 2. 创建元数据提取器\n",
        "#   2.1 自动生成节点内容的标题\n",
        "title_extractor = TitleExtractor(\n",
        "    nodes = 5  # 使用上下5个节点生成上下文标题\n",
        ")\n",
        "#   2.2 提取节点能回答的问题\n",
        "qa_extractor = QuestionsAnsweredExtractor(\n",
        "    questions=3  # 为每个节点生成能回答的3个问题\n",
        ")\n",
        "\n",
        "# 3. 创建数据处理管道\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        text_splitter,    # 步骤1：分割文档\n",
        "        title_extractor,  # 步骤2：提取标题\n",
        "        qa_extractor      # 步骤3：生成问题\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 4. 运行管道处理文档\n",
        "#   4.1 第一种写法\n",
        "pipelineNodes = pipeline.run(\n",
        "    documents=baseDocuments,  # 输入docs\n",
        "    in_place=True,        # 直接修改文档对象\n",
        "    show_progress= True,  # 显示进度条\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "963ffe4adc4a46e397c0053a2641462e",
            "3010163abc39461383aff863b16897dd",
            "6582f70cfdf64bc5861deb4c13381638",
            "812cfecbb2b14b0db18ab3cfdf17821e",
            "545c498e96e64cc89731b2c2af6bcc3b",
            "28809eedd40e4d47bc82bd74ffd3dad9",
            "c7a1870238c047d6b1560e29d90360a9",
            "d2f49382e7cd4b6d8c51d540435e6326",
            "e9748cd9e5924bcf993c3223b8c5edb4",
            "1a1227ef503d43be9b4db578ecf21317",
            "9c62252459c543efa59cfbeabf2b1b0d"
          ]
        },
        "id": "aL-lmjMnjKVe",
        "outputId": "c2bc1a4d-e051-4b05-e65f-5e78f0448f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "963ffe4adc4a46e397c0053a2641462e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [00:32<00:00,  4.63s/it]\n",
            "100%|██████████| 110/110 [04:38<00:00,  2.53s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for n in pipelineNodes[:4]:\n",
        "  print(f'{n.id_} -> {n.metadata[\"document_title\"].split(\"**Title:\")[1].replace(\"**\", \"\")}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HOOkKTlovHI",
        "outputId": "c897824e-8153-416a-89f8-eea2455835fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d6bbf91f-433f-4970-9847-2e06e730848b ->  数据库设计与SQL优化实战：从范式理论到AWS IAM跨账号安全访问  \n",
            "\n",
            "这个标题既涵盖了数据库设计与SQL查询优化的核心内容，也体现了AWS IAM跨账号访问的实际应用场景，体现了文档的技术深度与广度。\n",
            "18e9063c-2fae-4c84-b78a-a0b2e678eb61 ->  数据库设计与SQL优化实战：从范式理论到AWS IAM跨账号安全访问  \n",
            "\n",
            "这个标题既涵盖了数据库设计与SQL查询优化的核心内容，也体现了AWS IAM跨账号访问的实际应用场景，体现了文档的技术深度与广度。\n",
            "8e08e254-0c38-45c0-837c-7a4dd46c92f2 ->  数据库设计与SQL优化实战：从范式理论到AWS IAM跨账号安全访问  \n",
            "\n",
            "这个标题既涵盖了数据库设计与SQL查询优化的核心内容，也体现了AWS IAM跨账号访问的实际应用场景，体现了文档的技术深度与广度。\n",
            "939ed30a-9de3-496c-91a3-34cd14eae3e0 ->  数据库设计与SQL优化实战：从范式理论到AWS IAM跨账号安全访问  \n",
            "\n",
            "这个标题既涵盖了数据库设计与SQL查询优化的核心内容，也体现了AWS IAM跨账号访问的实际应用场景，体现了文档的技术深度与广度。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#   4.2 第二种写法\n",
        "from llama_index.core import VectorStoreIndex\n",
        "nodes_index = VectorStoreIndex.from_documents(\n",
        "    documents, transformations=[text_splitter, title_extractor, qa_extractor]\n",
        ")"
      ],
      "metadata": {
        "id": "ppKaoGL5wFEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 节点解析器、文本分割器\n"
      ],
      "metadata": {
        "id": "vSxpAjiDxRVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 单独使用\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "node_parser = SentenceSplitter(\n",
        "    chunk_size=1024,    # 块大小\n",
        "    chunk_overlap=256,  # 上下块覆盖大小\n",
        ")\n",
        "\n",
        "nodes = node_parser.get_nodes_from_documents(\n",
        "    documents=baseDocuments,    # 导入doc\n",
        "    show_progress=True,         # 显示处理进度\n",
        ")"
      ],
      "metadata": {
        "id": "W-41gTuRxQfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 转换使用\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "\n",
        "# 定义pipeline的操作序列\n",
        "pipeline = IngestionPipeline(transformations=[TokenTextSplitter()])\n",
        "\n",
        "# 执行nodes\n",
        "nodes = pipeline.run(documents=baseDocuments)"
      ],
      "metadata": {
        "id": "WcvhlKKBzpIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 索引使用   \n",
        "设置在transformations或全局设置中，以便在通过 .from_documents() 构建索引时自动使用"
      ],
      "metadata": {
        "id": "rNGIg2gX2M0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 数据管道\n",
        "输入数据中，这些Transformations会被应用到输入的数据中，最终生成node。这些node要么被返回要么被插入到向量数据库中。     \n",
        "下面是简单的使用："
      ],
      "metadata": {
        "id": "Je67mY-o49yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
        "\n",
        "# 创建pipeline转化\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        SentenceSplitter(chunk_size=1024, chunk_overlap=0),   # 定义划分node\n",
        "        TitleExtractor(),     # 给出 title\n",
        "        OpenAIEmbedding(),    # 创建 embedding\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 生成node\n",
        "tmpNode = pipeline.run(documents=baseDocuments)"
      ],
      "metadata": {
        "id": "FF9h-RWK49Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "连接到向量数据库  \n",
        "当输入数据被转换后，将embedding的node插入到远程向量数据库中。  "
      ],
      "metadata": {
        "id": "32Hwslgl7Rxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "from llama_index.core.ingestion import IngestionPipeline\n",
        "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
        "\n",
        "import qdrant_client\n",
        "\n",
        "# 创建Qdrant向量数据库\n",
        "client = qdrant_client.QdrantClient(location=\":memory:\")\n",
        "# 创建Qdrant向量存储实例\n",
        "vector_store = QdrantVectorStore(client=client, collection_name=\"test_store\")\n",
        "\n",
        "# 创建数据处理管道\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        SentenceSplitter(chunk_size=1024, chunk_overlap=256),   # 文本分割\n",
        "        TitleExtractor(),       # 提取块的标题\n",
        "        OpenAIEmbedding(),      # 生成embedding\n",
        "    ],\n",
        "    vector_store=vector_store   # 指定存储的位置\n",
        ")\n",
        "\n",
        "# 对数据进行处理\n",
        "pipeline.run(documents=baseDocuments)\n",
        "\n",
        "# 从向量数据库中创建index\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# 直接从数据库中创建索引\n",
        "index = VectorStoreIndex.from_vector_store(vector_store)"
      ],
      "metadata": {
        "id": "cLpmphWy7uGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 管道缓存  \n",
        "在IngestionPipeline中，可以缓存pipeline,这样可以节省后续使用相同数据转换的操作"
      ],
      "metadata": {
        "id": "g61pjKWjPor1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 存储pipeline\n",
        "pipeline.persist(f\"./pipeline_storage\")\n",
        "# 加载pipeline\n",
        "new_pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "        SentenceSplitter(chunk_size=1024, chunk_overlap=256),   # 文本分割\n",
        "        TitleExtractor(),       # 提取块的标题\n",
        "        OpenAIEmbedding(),      # 生成embedding\n",
        "    ],\n",
        "    vector_store=vector_store   # 指定存储的位置\n",
        ")\n",
        "new_pipeline.load(\"./pipeline_storage\")"
      ],
      "metadata": {
        "id": "XnXoen43PrgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面将pipeline数据存储到redis中"
      ],
      "metadata": {
        "id": "BdUHU_7lQnD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.extractors import TitleExtractor\n",
        "from llama_index.core.ingestion import IngestionPipeline, IngestionCache\n",
        "from llama_index.storage.kvstore.redis import RedisKVStore as RedisCache\n",
        "\n",
        "# 实例化 redis Cache\n",
        "ingest_cache = IngestionCache(\n",
        "    cache = RedisCache.from_host_and_port(host=\"localhost\", port=6379),\n",
        "    collection = \"my_test_cache\"\n",
        ")\n",
        "\n",
        "# 存储到redis中\n",
        "pipeline = IngestionPipeline(\n",
        "    transformations=[\n",
        "      SentenceSplitter(chunk_size=25, chunk_overlap=0),\n",
        "      TitleExtractor(),\n",
        "      OpenAIEmbedding(),\n",
        "    ],\n",
        "    cache=ingest_cache,\n",
        ")\n",
        "\n",
        "redis_cache_nodes = pipeline.run(documents=baseDocuments)"
      ],
      "metadata": {
        "id": "LYBaLSYsQqUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 索引"
      ],
      "metadata": {
        "id": "R3_j7ZEXT63I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fBQrNpBcRidw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
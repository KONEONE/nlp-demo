{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KONEONE/nlp-demo/blob/main/llmindex_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm2vCB8StJPG"
      },
      "source": [
        "# 模型调用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUx-kd0QtBDZ"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-core\n",
        "%pip install llama-index-llms-dashscope\n",
        "%pip install llama-index-indices-managed-dashscope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2xqz_SeGtO_8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DASHSCOPE_API_KEY\"] = 'sk-a49fcd63a06f4b669c38b1461a60d2e4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FzgExrfHuDkt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from llama_index.core import Settings\n",
        "from llama_index.llms.dashscope import DashScope\n",
        "\n",
        "# LlamaIndex默认使用的大模型被替换为百炼\n",
        "llm = DashScope(model_name=\"qwen-plus\", api_key=os.getenv(\"DASHSCOPE_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3xKv-UB3Csr",
        "outputId": "096490b0-c725-4430-d2f1-3d08e15110a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CompletionResponse(text='当然可以！你好呀！👋 很高兴认识你！\\n\\n我是通义千问（Qwen），一个来自阿里巴巴集团通义实验室的AI助手。你可以把我看作一个多才多艺的“百事通”，擅长各种技能，比如：\\n\\n✨ **知识小百科**：从科学常识到冷门 trivia，我都能和你聊一聊  \\n🎨 **创意小能手**：写故事、写公文、写邮件、写剧本，甚至写诗，都不在话下  \\n🧮 **逻辑小达人**：编程、数学问题？我也可以帮你理清思路  \\n🌐 **语言小天才**：中英文自由切换，还能支持其他语言哦  \\n💬 **聊天小达人**：闲聊八卦、情感倾诉，我也很在行！\\n\\n我最喜欢的就是和用户一起探索新知识、解决问题，让每一次对话都变得有趣又有用！  \\n如果你有任何问题或需要帮助，随时告诉我，我会尽力为你提供支持～\\n\\n那么，现在轮到你啦！😊 有什么想和我聊的吗？', additional_kwargs={}, raw=GenerationResponse(status_code=<HTTPStatus.OK: 200>, request_id='9e26fa49-67ff-924d-b388-87723d51ec4f', code='', message='', output=GenerationOutput(text=None, choices=[Choice(finish_reason='stop', message=Message({'role': 'assistant', 'content': '当然可以！你好呀！👋 很高兴认识你！\\n\\n我是通义千问（Qwen），一个来自阿里巴巴集团通义实验室的AI助手。你可以把我看作一个多才多艺的“百事通”，擅长各种技能，比如：\\n\\n✨ **知识小百科**：从科学常识到冷门 trivia，我都能和你聊一聊  \\n🎨 **创意小能手**：写故事、写公文、写邮件、写剧本，甚至写诗，都不在话下  \\n🧮 **逻辑小达人**：编程、数学问题？我也可以帮你理清思路  \\n🌐 **语言小天才**：中英文自由切换，还能支持其他语言哦  \\n💬 **聊天小达人**：闲聊八卦、情感倾诉，我也很在行！\\n\\n我最喜欢的就是和用户一起探索新知识、解决问题，让每一次对话都变得有趣又有用！  \\n如果你有任何问题或需要帮助，随时告诉我，我会尽力为你提供支持～\\n\\n那么，现在轮到你啦！😊 有什么想和我聊的吗？'}))], finish_reason=None), usage=GenerationUsage(input_tokens=19, output_tokens=220)), logprobs=None, delta=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.complete(\"你好，你可以做个自我介绍吗\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv_YmYQu40d_"
      },
      "source": [
        "## 使用Embedding模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikFxf5Vn3pmc"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-core\n",
        "%pip install llama-index-embeddings-dashscope\n",
        "%pip install llama-index-readers-file\n",
        "%pip install docx2txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEz8CDFE5bX2",
        "outputId": "6f69e07d-005f-4f1e-8f0d-44940b9555ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 : 风急天高猿啸哀 -> [1.5536729097366333, -2.237586736679077, 1.5397623777389526, -2.3466579914093018, 3.8610622882843018]\n",
            "1 : 渚清沙白鸟飞回 -> [1.1659477949142456, -0.7178032994270325, -2.5256457328796387, 4.588367938995361, -1.1069172620773315]\n",
            "2 : 无边落木萧萧下 -> [2.6992974281311035, 2.5143065452575684, 0.20655924081802368, 0.6846164464950562, 2.106255531311035]\n",
            "3 : 不尽长江滚滚来 -> [-1.2515695095062256, 2.7955071926116943, 1.8544834852218628, -2.3869540691375732, 1.76776123046875]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from llama_index.embeddings.dashscope import DashScopeEmbedding\n",
        "\n",
        "# 初始化 Embedding 模型\n",
        "embedder = DashScopeEmbedding(model_name=\"text-embedding-v1\", api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
        "\n",
        "text_to_embedding = [\"风急天高猿啸哀\", \"渚清沙白鸟飞回\", \"无边落木萧萧下\", \"不尽长江滚滚来\"]\n",
        "\n",
        "# 调用 Embedding 模型\n",
        "res_embeddings = embedder.get_text_embedding_batch(text_to_embedding)\n",
        "# 显示 Embedding 后结果\n",
        "for index, embedding in enumerate(res_embeddings):\n",
        "  print(f\"{index} : {text_to_embedding[index]} -> {embedding[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQQNLm3K77Km"
      },
      "source": [
        "## 文本排序"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDhiFYvp6v-y"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-postprocessor-dashscope-rerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f12_MY7G8Ocq",
        "outputId": "60c49482-f9c3-4c68-ed0f-60acd70618f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text:text01  Score:0.6934868738541691\n",
            "Text:text02  Score:0.30383120630110555\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.data_structs import Node\n",
        "from llama_index.core.schema import NodeWithScore\n",
        "from llama_index.postprocessor.dashscope_rerank import DashScopeRerank\n",
        "\n",
        "\n",
        "nodes = [\n",
        "    NodeWithScore(node=Node(text='text01'), score=0.7),\n",
        "    NodeWithScore(node=Node(text='text02'), score=0.8),\n",
        "]\n",
        "\n",
        "dashscope_rerank = DashScopeRerank(top_n=5, api_key=os.getenv(\"DASHSCOPE_API_KEY\"))\n",
        "\n",
        "res = dashscope_rerank.postprocess_nodes(nodes, query_str=\"text01?\")\n",
        "\n",
        "for r in res:\n",
        "  print(f\"Text:{r.node.get_content()}  Score:{r.score}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPaCNpA9RfwVHXN889n60Nz",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "graph_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
